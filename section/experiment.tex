\section{Experimental Setup}

\rt{I'd expect some of these to be discussed in related work.}

\sepfootnotecontent{sf:implementationComunica}{
   \ifanonymous
      \url{https://anonymous.4open.science/r/comunica-feature-link-traversal-AE1C}
   \else
      \url{https://github.com/constraintAutomaton/comunica-feature-link-traversal/tree/feature/shapeIndex}
   \fi
}

\sepfootnotecontent{sf:solidbench}{
   \url{https://github.com/SolidBench/SolidBench.js}
}

\sepfootnotecontent{sf:implementationQueryShapeContainment}{
   \ifanonymous
      \url{https://anonymous.4open.science/r/query-shape-detection-ED87/}
   \else
      \url{https://github.com/constraintAutomaton/query-shape-detection}
   \fi
}

\sepfootnotecontent{sf:shapeIndexGenerator}{
   \ifanonymous
      \url{https://anonymous.4open.science/r/rdf-dataset-fragmenter_js-08B9}
   \else
      \url{https://github.com/constraintAutomaton/rdf-dataset-fragmenter.js/tree/feature/shape-index-fragmentation-strategy}
   \fi
}

\sepfootnotecontent{sf:complementaryMaterial}{
   \ifanonymous
      \url{https://anonymous.4open.science/r/documentation-1A65}
   \else
      \url{https://github.com/shapeIndexComunicaExperiment/documentation}
   \fi
}

We implemented our approach using the LTQP version of the Comunica query engine~\cite{taelman_iswc_resources_comunica_2018}.
We chose Comunica due to its modularity~\cite{taelman_swj_componentsjs_2022} and its established use in several LTQP studies~\cite{Bogaerts2021LinkTW, Taelman2023, eschauzier_quweda_linkqueue_2023, Hanski2024, eschauzier_amw_rcubemetric_2024, tam2024opportunitiesshapebasedoptimizationlink}.
The implementation of our reachability criteria and the link queue filter is open source~\sepfootnote{sf:implementationComunica}, as well as our query-shape containment solver~\sepfootnote{sf:implementationQueryShapeContainment}.
We use SolidBench~\cite{Taelman2023}, based on the LDBC social network benchmark~\cite{Angles2020}, to evaluate our contribution. 
To facilitate this, we created an open-source module~\sepfootnote{sf:shapeIndexGenerator} to generate shape indexes in SolidBench, based on user-provided mappings between ShEx shapes and data model objects.
The shape annotated portion of the data model includes posts, comments on posts, user profiles, cities, and likes.
The datasets are Solid Pods~\cite{Taelman2023}
Each Solid Pod contains a shape index and separate files for each shape definition.
Some shapes are nested within others. 
For example, profiles are associated with cities, and comment are associated with posts.
Certain data model objects are materialized in a single file, while others are distributed across multiple files, depending on the pod instance.
The entire data model is available online~\sepfootnote{sf:solidbench}.




\rt{The following is lacking many details that are necessary to understand the experimental setup. I recommend expanding this section, and perhaps creating subsections for each experiment (or an enumeration).}
We designed several experiments to analyze and evaluate our approach.
First, we measure the execution time and results of our query-shape containment algorithm using the shapes from the study \rt{Which shapes are this exactly?}.
We also compare the state-of-the-art traversal algorithm \rt{I would not call this the state-of-the-art traversal algorithm. Just use the citation, or call it the optimal algorithm that does LTQP based on structural assumptions}, the LDP specification and type-index, and the LDP specification~\cite{Taelman2023} with our shape index approach in a network where every dataset provides a complete shape index with the most descriptive shapes.
Additionally, we evaluate the adaptivity of our approach by modulating the shape index information across the network.\rt{Unclear what this means.}
In one experiment, we examine the impact of query execution time in a network where 0\%, 20\%, 50\%, and 80\% of datasets \rt{What are datasets? I guess pods?} expose a shape index.
In another experiment, we assess the effect of having shape indexes with 20\%, 50\%, and 80\% entries using closed shapes.
In the final experiment, we evaluate the impact of using shapes that only incorporated data from the dataset itself and shapes that provided a minimal description of the data.\rt{Unclear what this means.}
For all experiments, we performed 50 repetitions and set a timeout of 2 minutes (120,000 ms).
To run our experiments, we used a machine with Ubuntu 20.04.6 LTS, featuring a 2x Hexacore Intel E5645 CPU and 24GB of RAM.
All our experiments are fully reproducible, and all raw data and complementary material is available online~\sepfootnote{sf:complementaryMaterial}.

%https://doc.ilabt.imec.be/ilabt/virtualwall/hardware.html#virtual-wall-2

