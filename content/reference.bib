@Article{Spasi2023,
  author    = {Mirko Spasi{\'{c}} and Milena Vujo{\v{s}}evi{\'{c}} Jani{\v{c}}i{\'{c}}},
  journal   = {Journal of Web Semantics},
  title     = {Solving the {SPARQL} query containment problem with {SpeCS}},
  year      = {2023},
  month     = apr,
  pages     = {100770},
  volume    = {76},
  comment   = {I have been told to be careful about the claim of that paper because it has been rejected by another journal because there was a problem in the approach.},
  doi       = {10.1016/j.websem.2022.100770},
  file      = {:papers/Solving the SPARQL query containment problem with SpeCS.pdf:PDF},
  groups    = {query containment bag semantic, query containment with RDF},
  priority  = {prio1},
  publisher = {Elsevier {BV}},
  url       = {https://doi.org/10.1016/j.websem.2022.100770},
}

@InBook{afariQCE,
  author     = {Foto Afrati, Rada Chirkova},
  chapter    = {2},
  pages      = {21-59},
  publisher  = {Springer Cham},
  title      = {Query Containment and Equivalence},
  year       = {2019},
  booktitle  = {Answering Queries Using Views, Second Edition},
  doi        = {https://doi.org/10.1007/978-3-031-01871-8},
  file       = {:papers/Query Containment and Equivalence.pdf:PDF;:papers/Query Containment and Equivalence/p23.jpg:JPG image},
  groups     = {query containment},
  ranking    = {rank5},
  readstatus = {read},
}

@InBook{afariAQD,
  author    = {Foto Afrati, Rada Chirkova},
  chapter   = {5},
  pages     = {125-142},
  publisher = {Springer Cham},
  title     = {Answering Queries in Presence of Dependencies},
  year      = {2019},
  booktitle = {Answering Queries Using Views, Second Edition},
  doi       = {https://doi.org/10.1007/978-3-031-01871-8},
  file      = {:papers/Answering Queries in Presence of Dependencies.pdf:PDF},
  groups    = {query containment},
  priority  = {prio3},
}

@Article{10.1145/3472391,
  author     = {Khamis, Mahmoud Abo and Kolaitis, Phokion G. and Ngo, Hung Q. and Suciu, Dan},
  journal    = {ACM Trans. Database Syst.},
  title      = {Bag Query Containment and Information Theory},
  year       = {2021},
  issn       = {0362-5915},
  month      = {sep},
  number     = {3},
  volume     = {46},
  abstract   = {The query containment problem is a fundamental algorithmic problem in data management. While this problem is well understood under set semantics, it is by far less understood under bag semantics. In particular, it is a long-standing open question whether or not the conjunctive query containment problem under bag semantics is decidable. We unveil tight connections between information theory and the conjunctive query containment under bag semantics. These connections are established using information inequalities, which are considered to be the laws of information theory. Our first main result asserts that deciding the validity of a generalization of information inequalities is many-one equivalent to the restricted case of conjunctive query containment in which the containing query is acyclic; thus, either both these problems are decidable or both are undecidable. Our second main result identifies a new decidable case of the conjunctive query containment problem under bag semantics. Specifically, we give an exponential-time algorithm for conjunctive query containment under bag semantics, provided the containing query is chordal and admits a simple junction tree.},
  address    = {New York, NY, USA},
  articleno  = {12},
  doi        = {10.1145/3472391},
  file       = {:papers/Bag Query Containment and Information Theory.pdf:PDF},
  groups     = {reading, query containment bag semantic},
  issue_date = {September 2021},
  keywords   = {information theory, entropy, Query containment, bag semantics},
  numpages   = {39},
  priority   = {prio1},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3472391},
}

@Article{Chekol2018,
  author    = {Melisachew Wudage Chekol and J{\'{e}}r{\^{o}}me Euzenat and Pierre Genev{\`{e}}s and Nabil Layaïda},
  journal   = {Journal on Data Semantics},
  title     = {{SPARQL} Query Containment Under Schema},
  year      = {2018},
  month     = may,
  number    = {3},
  pages     = {133--154},
  volume    = {7},
  doi       = {10.1007/s13740-018-0087-1},
  file      = {:papers/SPARQL Query Containment under Schema.pdf:PDF},
  groups    = {query containment bag semantic, query containment with RDF},
  priority  = {prio1},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007/s13740-018-0087-1},
}

@Misc{2112.11796,
  author     = {Thomas Delva and Anastasia Dimou and Maxime Jakubowski and Jan Van den Bussche},
  title      = {Shape Fragments},
  year       = {2021},
  comment    = {It's a bit complicated to understand but I think the idea of converting the shape into a query or converting the shape directly into a canonical database (not in the paper) might be a very good approach. But the query are complicated and the software proposed is a naive implementation.},
  eprint     = {arXiv:2112.11796},
  file       = {:papers/Shape Fragments.pdf:PDF},
  groups     = {shape},
  ranking    = {rank4},
  readstatus = {skimmed},
}

@Misc{koutisLecture,
  author = {Paris Koutris},
  title  = {Lecture 2: Query Containment},
  file   = {:papers/Koutris_query_containment.pdf:PDF},
  groups = {query containment},
}

@InBook{Chirkova2009,
  author    = {Chirkova, Rada},
  editor    = {LIU, LING and {\"O}ZSU, M. TAMER},
  pages     = {2249--2253},
  publisher = {Springer US},
  title     = {Query Containment},
  year      = {2009},
  address   = {Boston, MA},
  isbn      = {978-0-387-39940-9},
  booktitle = {Encyclopedia of Database Systems},
  doi       = {10.1007/978-0-387-39940-9_1269},
  file      = {:papers/Query Containment.pdf:PDF},
  groups    = {query containment},
  priority  = {prio1},
  url       = {https://doi.org/10.1007/978-0-387-39940-9_1269},
}

@InProceedings{10.1145/275487.275511,
  author    = {Kolaitis, Phokion G. and Vardi, Moshe Y.},
  booktitle = {Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems},
  title     = {Conjunctive-Query Containment and Constraint Satisfaction},
  year      = {1998},
  address   = {New York, NY, USA},
  pages     = {205–213},
  publisher = {Association for Computing Machinery},
  series    = {PODS '98},
  doi       = {10.1145/275487.275511},
  file      = {:papers/Conjunctive query containment and constraint satisfaction.pdf:PDF},
  groups    = {query containment},
  isbn      = {0897919963},
  location  = {Seattle, Washington, USA},
  numpages  = {9},
  priority  = {prio1},
  url       = {https://doi.org/10.1145/275487.275511},
}

@InProceedings{Ullman1997,
  author    = {Ullman, Jeffrey D.},
  booktitle = {Database Theory --- ICDT '97},
  title     = {Information integration using logical views},
  year      = {1997},
  address   = {Berlin, Heidelberg},
  editor    = {Afrati, Foto and Kolaitis, Phokion},
  pages     = {19--40},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {A number of ideas concerning information-integration tools can be thought of as constructing answers to queries using views that represent the capabilities of information sources. We review the formal basis of these techniques, which are closely related to containment algorithms for conjunctive queries and/or Datalog programs. Then we compare the approaches taken by AT{\&}T Labs' ``Information Manifold'' and the Stanford ``Tsimmis'' project in these terms.},
  file      = {:papers/Information integration using logical views.pdf:PDF},
  groups    = {query containment},
  isbn      = {978-3-540-49682-3},
  priority  = {prio2},
}

@InProceedings{10.1007/978-3-319-68288-4_7,
  author        = {Boneva, Iovka and Labra Gayo, Jose E. and Prud’hommeaux, Eric G.},
  booktitle     = {The Semantic Web – ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21–25, 2017, Proceedings, Part I},
  title         = {Semantics and Validation of Shapes Schemas for RDF},
  year          = {2017},
  address       = {Berlin, Heidelberg},
  pages         = {104–120},
  publisher     = {Springer-Verlag},
  abstract      = {We present a formal semantics and proof of soundness for shapes schemas, an expressive schema language for RDF graphs that is the foundation of Shape Expressions Language 2.0. It can be used to describe the vocabulary and the structure of an RDF graph, and to constrain the admissible properties and values for nodes in that graph. The language defines a typing mechanism called shapes against which nodes of the graph can be checked. It includes an algebraic grouping operator, a choice operator and cardinality constraints for the number of allowed occurrences of a property. Shapes can be combined using Boolean operators, and can use possibly recursive references to other shapes.We describe the syntax of the language and define its semantics. The semantics is proven to be well-defined for schemas that satisfy a reasonable syntactic restriction, namely stratified use of negation and recursion. We present two algorithms for the validation of an RDF graph against a shapes schema. The first algorithm is a direct implementation of the semantics, whereas the second is a non-trivial improvement. We also briefly give implementation guidelines.},
  comment-id357 = {Cet article a une bonne formulation des formes, je pense qu'il peut être un bon point de départ pour ma propre formulation, il y a aussi une bonne gestion des négations. Par contre le problème de transformer les formes dans une formulation compatible avec le problème de containement reste un problème.},
  doi           = {10.1007/978-3-319-68288-4_7},
  file          = {:papers/Semantics and Validation of Shapes Schemas for RDF.pdf:PDF},
  groups        = {shape},
  isbn          = {978-3-319-68287-7},
  location      = {Vienna, Austria},
  numpages      = {17},
  ranking       = {rank5},
  readstatus    = {read},
  url           = {https://doi.org/10.1007/978-3-319-68288-4_7},
}

@Misc{afrati2020complexity,
  author        = {Foto N. Afrati and Matthew Damigos},
  title         = {On the complexity of query containment and computing certain answers in the presence of ACs},
  year          = {2020},
  archiveprefix = {arXiv},
  comment-id357 = {Help to explain the cannonical database for query with arithmetic comparator},
  eprint        = {2008.10986},
  file          = {:papers/On the Complexity of Query Containment and Computing Certain Answers in the Presence of ACs.pdf:PDF},
  groups        = {query containment},
  primaryclass  = {cs.DB},
  ranking       = {rank4},
  readstatus    = {skimmed},
}

@Article{Leinberger2020DecidingSS,
  author   = {Martin Leinberger and Philipp Seifer and Tjitze Rienstra and Ralf Lammel and Steffen Staab},
  journal  = {ArXiv},
  title    = {Deciding SHACL Shape Containment through Description Logics Reasoning (Extended Version)},
  year     = {2020},
  volume   = {abs/2008.13603},
  file     = {:papers/Deciding SHACL Shape Containment through Description Logics Reasoning Extended Version.pdf:PDF},
  groups   = {shape containment},
  priority = {prio1},
  url      = {https://api.semanticscholar.org/CorpusID:221377301},
}

@Article{Pareti2020SHACLSA,
  author   = {Paolo Pareti and G. Konstantinidis and Fabio Mogavero and Timothy J. Norman},
  journal  = {ArXiv},
  title    = {SHACL Satisfiability and Containment (Extended Paper)},
  year     = {2020},
  volume   = {abs/2009.09806},
  file     = {:papers/SHACL Satisfiability and Containment Extended Paper.pdf:PDF},
  groups   = {shape containment},
  priority = {prio1},
  url      = {https://api.semanticscholar.org/CorpusID:221818992},
}

@Article{Staworko2018ContainmentOS,
  author   = {Slawomir Staworko and Piotr Wieczorek},
  journal  = {Proceedings of the 38th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
  title    = {Containment of Shape Expression Schemas for RDF},
  year     = {2018},
  file     = {:papers/Containment of Shape Expression Schemas for RDF.pdf:PDF},
  groups   = {shape containment, reading},
  priority = {prio1},
  url      = {https://api.semanticscholar.org/CorpusID:4337350},
}

@Article{Afrati2010,
  author     = {Foto N. Afrati and Matthew Damigos and Manolis Gergatsoulis},
  journal    = {Information Processing Letters},
  title      = {Query containment under bag and bag-set semantics},
  year       = {2010},
  month      = apr,
  number     = {10},
  pages      = {360--369},
  volume     = {110},
  comment    = {Very good paper to solve the QC problem with bag semantic-set describe well their approach and the complexity. Will be useful, if I need to implement something or to describe theoritical points.},
  doi        = {10.1016/j.ipl.2010.02.017},
  file       = {:papers/Query containment under bag and bag set semantics.pdf:PDF},
  groups     = {query containment bag semantic},
  priority   = {prio1},
  publisher  = {Elsevier {BV}},
  ranking    = {rank5},
  readstatus = {read},
  url        = {https://doi.org/10.1016/j.ipl.2010.02.017},
}

@Misc{kopparty2010homomorphism,
  author        = {Swastik Kopparty and Benjamin Rossman},
  title         = {The Homomorphism Domination Exponent},
  year          = {2010},
  archiveprefix = {arXiv},
  eprint        = {1004.2485},
  file          = {:papers/The Homomorphism Domination Exponent.pdf:PDF},
  groups        = {query containment bag semantic},
  primaryclass  = {math.CO},
}

@Article{Saleem2018,
  author    = {Muhammad Saleem and Ali Hasnain and Axel-Cyrille Ngonga Ngomo},
  journal   = {Journal of Web Semantics},
  title     = {{LargeRDFBench}: A billion triples benchmark for {SPARQL} endpoint federation},
  year      = {2018},
  month     = jan,
  pages     = {85--125},
  volume    = {48},
  doi       = {10.1016/j.websem.2017.12.005},
  file      = {:papers/LargeRDFBench A billion triples benchmark for SPARQL endpoint.pdf:PDF},
  groups    = {federated queries},
  publisher = {Elsevier {BV}},
  url       = {https://doi.org/10.1016/j.websem.2017.12.005},
}

@InProceedings{10.1145/153850.153856,
  author    = {Chaudhuri, Surajit and Vardi, Moshe Y.},
  booktitle = {Proceedings of the Twelfth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems},
  title     = {Optimization of Real Conjunctive Queries},
  year      = {1993},
  address   = {New York, NY, USA},
  pages     = {59–70},
  publisher = {Association for Computing Machinery},
  series    = {PODS '93},
  doi       = {10.1145/153850.153856},
  file      = {:papers/Optimization of real conjunctive queries.pdf:PDF},
  groups    = {query containment bag semantic},
  isbn      = {0897915933},
  location  = {Washington, D.C., USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/153850.153856},
}

@Online{spapeExpressionConvert,
  author   = {W3C},
  file     = {:papers/SPARQL Queries to Validate Shape Expressions.pdf:PDF},
  groups   = {shape},
  priority = {prio1},
  title    = {SPARQL Queries to Validate Shape Expressions (informative)},
  url      = {https://www.w3.org/2013/ShEx/toSPARQL.html},
  urldate  = {2023-09-11},
  year     = {2013},
}

@InProceedings{Abbas2017,
  author     = {Abbas, Abdullah and Genev{\`e}s, Pierre and Roisin, C{\'e}cile and Laya{\"i}da, Nabil},
  booktitle  = {Advances in Databases and Information Systems},
  title      = {SPARQL Query Containment with ShEx Constraints},
  year       = {2017},
  address    = {Cham},
  editor     = {Kirikova, M{\={a}}r{\={\i}}te and N{\o}rv{\aa}g, Kjetil and Papadopoulos, George A.},
  pages      = {343--356},
  publisher  = {Springer International Publishing},
  abstract   = {ShEx (Shape Expressions) is a language for expressing constraints on RDF graphs. We consider the problem of SPARQL query containment in the presence of ShEx constraints. We first propose a sound and complete procedure for the problem of containment with ShEx, considering several SPARQL fragments. Particularly our procedure considers OPTIONAL query patterns, that turns out to be an important fragment to be studied with schemas. We then show the complexity bounds of our problem with respect to the fragments considered. To the best of our knowledge, this is the first work addressing SPARQL query containment in the presence of ShEx constraints.},
  comment    = {what they do is that they use the shape to transform the queries that have filters to delete them when the query will for certain don't respect the containt of the data. Given this transformation some queries can become equivalent. Also if the query is only a BGP then we can simply validate it against the shape if we delete the cardinatity of the operators.},
  file       = {:papers/SPARQL Query Containment with ShEx Constraints.pdf:PDF},
  groups     = {query containment with RDF, query containment bag semantic},
  isbn       = {978-3-319-66917-5},
  ranking    = {rank5},
  readstatus = {read},
}

@InProceedings{Kostylev2015,
  author    = {Kostylev, Egor V. and Reutter, Juan L. and Romero, Miguel and Vrgo{\v{c}}, Domagoj},
  booktitle = {The Semantic Web - ISWC 2015},
  title     = {SPARQL with Property Paths},
  year      = {2015},
  address   = {Cham},
  editor    = {Arenas, Marcelo and Corcho, Oscar and Simperl, Elena and Strohmaier, Markus and d'Aquin, Mathieu and Srinivas, Kavitha and Groth, Paul and Dumontier, Michel and Heflin, Jeff and Thirunarayan, Krishnaprasad and Thirunarayan, Krishnaprasad and Staab, Steffen},
  pages     = {3--18},
  publisher = {Springer International Publishing},
  abstract  = {The original SPARQL proposal was often criticized for its inability to navigate through the structure of RDF documents. For this reason property paths were introduced in SPARQL 1.1, but up to date there are no theoretical studies examining how their addition to the language affects main computational tasks such as query evaluation, query containment, and query subsumption. In this paper we tackle all of these problems and show that although the addition of property paths has no impact on query evaluation, they do make the containment and subsumption problems substantially more difficult.},
  file      = {:papers/The Semantic Web -ISWC 2015 14th International Semantic Web Conference:},
  groups    = {query containment with RDF},
  isbn      = {978-3-319-25007-6},
}

@InProceedings{10.1145/2594538.2594542,
  author    = {Pichler, Reinhard and Skritek, Sebastian},
  booktitle = {Proceedings of the 33rd ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
  title     = {Containment and Equivalence of Well-Designed SPARQL},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {39–50},
  publisher = {Association for Computing Machinery},
  series    = {PODS '14},
  abstract  = {Query containment and query equivalence constitute important computational problems in the context of static query analysis and optimization. While these problems have been intensively studied for fragments of relational calculus, almost no works exist for the semantic web query language SPARQL. In this paper, we carry out a comprehensive complexity analysis of containment and equivalence for several fragments of SPARQL: we start with the fundamental fragment of well-designed SPARQL restricted to the AND and OPTIONAL operator. We then study basic extensions in the form of the UNION operator and/or projection. The results obtained range from NP-completeness to undecidability.},
  doi       = {10.1145/2594538.2594542},
  file      = {:papers/Containment and Equivalence of Well Designed SPARQL.pdf:PDF},
  groups    = {query containment with RDF},
  isbn      = {9781450323758},
  keywords  = {query containment, RDF, semantic web, SPARQL},
  location  = {Snowbird, Utah, USA},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2594538.2594542},
}

@Article{10.1145/2500130,
  author     = {Letelier, Andr\'{e}s and P\'{e}rez, Jorge and Pichler, Reinhard and Skritek, Sebastian},
  journal    = {ACM Trans. Database Syst.},
  title      = {Static Analysis and Optimization of Semantic Web Queries},
  year       = {2013},
  issn       = {0362-5915},
  month      = {dec},
  number     = {4},
  volume     = {38},
  abstract   = {Static analysis is a fundamental task in query optimization. In this article we study static analysis and optimization techniques for SPARQL, which is the standard language for querying Semantic Web data. Of particular interest for us is the optionality feature in SPARQL. It is crucial in Semantic Web data management, where data sources are inherently incomplete and the user is usually interested in partial answers to queries. This feature is one of the most complicated constructors in SPARQL and also the one that makes this language depart from classical query languages such as relational conjunctive queries. We focus on the class of well-designed SPARQL queries, which has been proposed in the literature as a fragment of the language with good properties regarding query evaluation. We first propose a tree representation for SPARQL queries, called pattern trees, which captures the class of well-designed SPARQL graph patterns. Among other results, we propose several rules that can be used to transform pattern trees into a simple normal form, and study equivalence and containment. We also study the evaluation and enumeration problems for this class of queries.},
  address    = {New York, NY, USA},
  articleno  = {25},
  doi        = {10.1145/2500130},
  file       = {:papers/Static Analysis and Optimization of Semantic Web Queries.pdf:PDF},
  groups     = {query containment with RDF},
  issue_date = {November 2013},
  keywords   = {query containment, Semantic Web, RDF, SPARQL, Optimization},
  numpages   = {45},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2500130},
}

@InProceedings{10.1145/3366423.3380177,
  author     = {Azzam, Amr and Fern\'{a}ndez, Javier D. and Acosta, Maribel and Beno, Martin and Polleres, Axel},
  booktitle  = {Proceedings of The Web Conference 2020},
  title      = {SMART-KG: Hybrid Shipping for SPARQL Querying on the Web},
  year       = {2020},
  address    = {New York, NY, USA},
  pages      = {984–994},
  publisher  = {Association for Computing Machinery},
  series     = {WWW '20},
  abstract   = {While Linked Data (LD) provides standards for publishing (RDF) and (SPARQL) querying Knowledge Graphs (KGs) on the Web, serving, accessing and processing such open, decentralized KGs is often practically impossible, as query timeouts on publicly available SPARQL endpoints show. Alternative solutions such as Triple Pattern Fragments (TPF) attempt to tackle the problem of availability by pushing query processing workload to the client side, but suffer from unnecessary transfer of irrelevant data on complex queries with large intermediate results. In this paper we present smart-KG, a novel approach to share the load between servers and clients, while significantly reducing data transfer volume, by combining TPF with shipping compressed KG partitions. Our evaluations show that smart-KG outperforms state-of-the-art client-side solutions and increases server-side availability towards more cost-effective and balanced hosting of open and decentralized KGs.},
  comment    = {When I will be doing join optimization maybe the paper will be more useful, but for the moment I don't think it helped  a lot internal partition.},
  doi        = {10.1145/3366423.3380177},
  file       = {:papers/SMART KG Hybrid Shipping for SPARQL Querying on the Web.pdf:PDF},
  groups     = {charateristic set},
  isbn       = {9781450370233},
  location   = {Taipei, Taiwan},
  numpages   = {11},
  ranking    = {rank3},
  readstatus = {skimmed},
  url        = {https://doi.org/10.1145/3366423.3380177},
}

@Article{Neumann2011CharacteristicSA,
  author     = {Thomas Neumann and Guido Moerkotte},
  journal    = {2011 IEEE 27th International Conference on Data Engineering},
  title      = {Characteristic sets: Accurate cardinality estimation for RDF queries with multiple joins},
  year       = {2011},
  pages      = {984-994},
  comment    = {Je pense que cela ressemble beaucoup a shape, donc une approche de convertir des shape en une approximation de caracteristique set serait bien.},
  file       = {:papers/Characteristic sets Accurate cardinality estimation for RDF queries with multiple joins.pdf:PDF},
  groups     = {charateristic set},
  ranking    = {rank5},
  readstatus = {skimmed},
  url        = {https://api.semanticscholar.org/CorpusID:2208604},
}

@Article{Meimaris2017ExtendedCS,
  author  = {Marios Meimaris and George Papastefanatos and Nikos Mamoulis and Ioannis Anagnostopoulos},
  journal = {2017 IEEE 33rd International Conference on Data Engineering (ICDE)},
  title   = {Extended Characteristic Sets: Graph Indexing for SPARQL Query Optimization},
  year    = {2017},
  pages   = {497-508},
  file    = {:papers/Extended Characteristic Sets Graph Indexing for SPARQL Query Optimization.pdf:PDF},
  groups  = {charateristic set},
  url     = {https://api.semanticscholar.org/CorpusID:3535607},
}

@Article{Meimaris2018HierarchicalCS,
  author  = {Marios Meimaris and George Papastefanatos},
  journal = {ArXiv},
  title   = {Hierarchical Characteristic Set Merging for Optimizing SPARQL Queries in Heterogeneous RDF},
  year    = {2018},
  volume  = {abs/1809.02345},
  file    = {:papers/Hierarchical Characteristic Set Merging for Optimizing SPARQL Queries in Heterogeneous RDF.pdf:PDF},
  groups  = {charateristic set},
  url     = {https://api.semanticscholar.org/CorpusID:52176979},
}

@InProceedings{staworko_et_al:LIPIcs:2015:4985,
  author    = {Slawek Staworko and Iovka Boneva and Jose E. Labra Gayo and Samuel Hym and Eric G. Prud'hommeaux and Harold Solbrig},
  booktitle = {18th International Conference on Database Theory (ICDT 2015)},
  title     = {{Complexity and Expressiveness of ShEx for RDF}},
  year      = {2015},
  address   = {Dagstuhl, Germany},
  editor    = {Marcelo Arenas and Mart{\'i}n Ugarte},
  pages     = {195--211},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  series    = {Leibniz International Proceedings in Informatics (LIPIcs)},
  volume    = {31},
  annote    = {Keywords: RDF, Schema, Graph topology, Validation, Complexity, Expressiveness},
  doi       = {10.4230/LIPIcs.ICDT.2015.195},
  groups    = {shape},
  isbn      = {978-3-939897-79-8},
  issn      = {1868-8969},
  url       = {http://drops.dagstuhl.de/opus/volltexte/2015/4985},
  urn       = {urn:nbn:de:0030-drops-49856},
}

@Misc{zervakis2019efficient,
  author        = {Lefteris Zervakis and Vinay Setty and Christos Tryfonopoulos and Katja Hose},
  title         = {Efficient Continuous Multi-Query Processing over Graph Streams},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1902.05134},
  file          = {:papers/Efﬁcient Continuous Multi-Query Processing over Graph Streams:},
  groups        = {query containment bag semantic},
  primaryclass  = {cs.DS},
}

@InProceedings{Hartig2012,
  author       = {Hartig, Olaf and Freytag, Johann-Christoph},
  booktitle    = {Conference on Hypertext and Social Media},
  title        = {Foundations of Traversal Based Query Execution over Linked Data},
  publisher    = {ACM},
  series       = {HT '12},
  abstract     = {Query execution over the Web of Linked Data has attracted much attention recently. A particularly interesting approach is link traversal based query execution which proposes to integrate the traversal of data links into the creation of query results. Hence -in contrast to traditional query execution paradigms- this does not assume a fixed set of relevant data sources beforehand; instead, the traversal process discovers data and data sources on the fly and, thus, enables applications to tap the full potential of the Web.While several authors have studied possibilities to implement the idea of link traversal based query execution and to optimize query execution in this context, no work exists that discusses theoretical foundations of the approach in general. Our paper fills this gap.We introduce a well-defined semantics for queries that may be executed using a link traversal based approach. Based on this semantics we formally analyze properties of such queries. In particular, we study the computability of queries as well as the implications of querying a potentially infinite Web of Linked Data. Our results show that query computation in general is not guaranteed to terminate and that for any given query it is undecidable whether the execution terminates. Furthermore, we define an abstract execution model that captures the integration of link traversal into the query execution process. Based on this model we prove the soundness and completeness of link traversal based query execution and analyze an existing implementation approach.},
  address.bak  = {New York, NY, USA},
  doi.bak      = {10.1145/2309996.2310005},
  groups       = {Link traversal, Link Traversal Query Processing},
  isbn         = {9781450313353},
  keywords     = {link traversal based query execution, computability, query semantics, web of data, linked data},
  location.bak = {Milwaukee, Wisconsin, USA},
  numpages.bak = {10},
  pages.bak    = {43–52},
  ranking      = {rank5},
  readstatus   = {read},
  url.bak      = {https://doi.bak.org/10.1145/2309996.2310005},
  year.bak     = {2012},
}

@InProceedings{10.1145/2661829.2661876,
  author    = {Wu, Buwen and Zhou, Yongluan and Yuan, Pingpeng and Jin, Hai and Liu, Ling},
  booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
  title     = {SemStore: A Semantic-Preserving Distributed RDF Triple Store},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {509–518},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '14},
  abstract  = {The flexibility of the RDF data model has attracted an increasing number of organizations to store their data in an RDF format. With the rapid growth of RDF datasets, we envision that it is inevitable to deploy a cluster of computing nodes to process large-scale RDF data in order to deliver desirable query performance. In this paper, we address the challenging problems of data partitioning and query optimization in a scale-out RDF engine. We identify that existing approaches only focus on using fine-grained structural information for data partitioning, and hence fail to localize many types of complex queries. We then propose a radically different approach, where a coarse-grained structure, namely Rooted Sub-Graph (RSG), is used as the partition unit. By doing so, we can capture structural information at a much greater scale and hence are able to localize many complex queries. We also propose a k-means partitioning algorithm for allocating the RSGs onto the computing nodes as well as a query optimization strategy to minimize the inter-node communication during query processing. An extensive experimental study using benchmark datasets and real dataset shows that our engine, SemStore, outperforms existing systems by orders of magnitudes in terms of query response time.},
  doi       = {10.1145/2661829.2661876},
  file      = {:papers/SemStore A Semantic Preserving Distributed RDF Triple Store.pdf:PDF},
  groups    = {query decomposition},
  isbn      = {9781450325981},
  keywords  = {sparql, rdf, query processing, partitioning},
  location  = {Shanghai, China},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2661829.2661876},
}

@Article{10.14778/2977797.2977806,
  author     = {Sch\"{a}tzle, Alexander and Przyjaciel-Zablocki, Martin and Skilevic, Simon and Lausen, Georg},
  journal    = {Proc. VLDB Endow.},
  title      = {S2RDF: RDF Querying with SPARQL on Spark},
  year       = {2016},
  issn       = {2150-8097},
  month      = {jun},
  number     = {10},
  pages      = {804–815},
  volume     = {9},
  abstract   = {RDF has become very popular for semantic data publishing due to its flexible and universal graph-like data model. Thus, the ever-increasing size of RDF data collections raises the need for scalable distributed approaches. We endorse the usage of existing infrastructures for Big Data processing like Hadoop for this purpose. Yet, SPARQL query performance is a major challenge as Hadoop is not intentionally designed for RDF processing. Existing approaches often favor certain query pattern shapes while performance drops significantly for other shapes. In this paper, we introduce a novel relational partitioning schema for RDF data called ExtVP that uses a semi-join based preprocessing, akin to the concept of Join Indices in relational databases, to efficiently minimize query input size regardless of its pattern shape and diameter. Our prototype system S2RDF is built on top of Spark and uses SQL to execute SPARQL queries over ExtVP. We demonstrate its superior performance in comparison to state of the art SPARQL-on-Hadoop approaches.},
  doi        = {10.14778/2977797.2977806},
  file       = {:papers/RDF Querying with SPARQL on Spark.pdf:PDF},
  groups     = {query decomposition},
  issue_date = {June 2016},
  numpages   = {12},
  publisher  = {VLDB Endowment},
  url        = {https://doi.org/10.14778/2977797.2977806},
}

@InProceedings{10.1145/2588555.2594535,
  author    = {Papailiou, Nikolaos and Tsoumakos, Dimitrios and Konstantinou, Ioannis and Karras, Panagiotis and Koziris, Nectarios},
  booktitle = {Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data},
  title     = {H2RDF+: An Efficient Data Management System for Big RDF Graphs},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {909–912},
  publisher = {Association for Computing Machinery},
  series    = {SIGMOD '14},
  abstract  = {The proliferation of data in RDF format has resulted in the emergence of a plethora of specialized management systems. While the ability to adapt to the complexity of a SPARQL query -- given their inherent diversity -- is crucial, current approaches do not scale well when faced with substantially complex, non-selective joins, resulting in exponential growth of execution times. In this demonstration we present H2 RDF+, an RDF store that efficiently performs distributed Merge and Sort-Merge joins using a multiple-index scheme over HBase indexes. Through a greedy planner that incorporates our cost-model, it adaptively commands for either single or multi-machine query execution based on join complexity. In this paper, we present its key scientific contributions and allow participants to interact with an H2RDF+ deployment over a Cloud infrastructure. Using a web-based GUI we allow users to load different datasets (both real and synthetic), apply any query (custom or predefined) and monitor its execution. By allowing real-time inspection of cluster status, response times and committed resources the audience will evaluate the validity of H2RDF+'s claims and perform direct comparisons to two other state-of-the-art RDF stores.},
  doi       = {10.1145/2588555.2594535},
  file      = {:papers/An Efﬁcient Data Management System for Big.pdf:PDF},
  groups    = {query decomposition},
  isbn      = {9781450323765},
  keywords  = {rdf, joins, nosql, sparql, hbase, mapreduce, hadoop},
  location  = {Snowbird, Utah, USA},
  numpages  = {4},
  url       = {https://doi.org/10.1145/2588555.2594535},
}

@InProceedings{10.1145/2661829.2661876,
  author    = {Wu, Buwen and Zhou, Yongluan and Yuan, Pingpeng and Jin, Hai and Liu, Ling},
  booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
  title     = {SemStore: A Semantic-Preserving Distributed RDF Triple Store},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {509–518},
  publisher = {Association for Computing Machinery},
  series    = {CIKM '14},
  abstract  = {The flexibility of the RDF data model has attracted an increasing number of organizations to store their data in an RDF format. With the rapid growth of RDF datasets, we envision that it is inevitable to deploy a cluster of computing nodes to process large-scale RDF data in order to deliver desirable query performance. In this paper, we address the challenging problems of data partitioning and query optimization in a scale-out RDF engine. We identify that existing approaches only focus on using fine-grained structural information for data partitioning, and hence fail to localize many types of complex queries. We then propose a radically different approach, where a coarse-grained structure, namely Rooted Sub-Graph (RSG), is used as the partition unit. By doing so, we can capture structural information at a much greater scale and hence are able to localize many complex queries. We also propose a k-means partitioning algorithm for allocating the RSGs onto the computing nodes as well as a query optimization strategy to minimize the inter-node communication during query processing. An extensive experimental study using benchmark datasets and real dataset shows that our engine, SemStore, outperforms existing systems by orders of magnitudes in terms of query response time.},
  doi       = {10.1145/2661829.2661876},
  file      = {:papers/A Semantic Preserving Distributed RDF Triple Store.pdf:PDF},
  groups    = {query decomposition},
  isbn      = {9781450325981},
  keywords  = {partitioning, rdf, query processing, sparql},
  location  = {Shanghai, China},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2661829.2661876},
}

@InProceedings{Montoya2017,
  author     = {Montoya, Gabriela and Skaf-Molli, Hala and Hose, Katja},
  booktitle  = {The Semantic Web -- ISWC 2017},
  title      = {The Odyssey Approach for Optimizing Federated SPARQL Queries},
  year       = {2017},
  address    = {Cham},
  editor     = {d'Amato, Claudia and Fernandez, Miriam and Tamma, Valentina and Lecue, Freddy and Cudr{\'e}-Mauroux, Philippe and Sequeda, Juan and Lange, Christoph and Heflin, Jeff},
  pages      = {471--489},
  publisher  = {Springer International Publishing},
  abstract   = {Answering queries over a federation of SPARQL endpoints requires combining data from more than one data source. Optimizing queries in such scenarios is particularly challenging not only because of (i) the large variety of possible query execution plans that correctly answer the query but also because (ii) there is only limited access to statistics about schema and instance data of remote sources. To overcome these challenges, most federated query engines rely on heuristics to reduce the space of possible query execution plans or on dynamic programming strategies to produce optimal plans. Nevertheless, these plans may still exhibit a high number of intermediate results or high execution times because of heuristics and inaccurate cost estimations. In this paper, we present Odyssey, an approach that uses statistics that allow for a more accurate cost estimation for federated queries and therefore enables Odyssey to produce better query execution plans. Our experimental results show that Odyssey produces query execution plans that are better in terms of data transfer and execution time than state-of-the-art optimizers. Our experiments using the FedBench benchmark show execution time gains of at least 25 times on average.},
  comment    = {The paper is very interesting and can be a great base for the federated query approach even for the LTQP one I think I can get some good insight and compare the particularity of this problem with the approach of that paper.},
  file       = {:papers/The Odyssey Approach for Optimizing Federated.pdf:PDF},
  groups     = {charateristic set, federated queries},
  isbn       = {978-3-319-68288-4},
  ranking    = {rank5},
  readstatus = {read},
}

@InProceedings{Schwarte2011,
  author    = {Schwarte, Andreas and Haase, Peter and Hose, Katja and Schenkel, Ralf and Schmidt, Michael},
  booktitle = {The Semantic Web -- ISWC 2011},
  title     = {FedX: Optimization Techniques for Federated Query Processing on Linked Data},
  year      = {2011},
  address   = {Berlin, Heidelberg},
  editor    = {Aroyo, Lora and Welty, Chris and Alani, Harith and Taylor, Jamie and Bernstein, Abraham and Kagal, Lalana and Noy, Natasha and Blomqvist, Eva},
  pages     = {601--616},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Motivated by the ongoing success of Linked Data and the growing amount of semantic data sources available on the Web, new challenges to query processing are emerging. Especially in distributed settings that require joining data provided by multiple sources, sophisticated optimization techniques are necessary for efficient query processing. We propose novel join processing and grouping techniques to minimize the number of remote requests, and develop an effective solution for source selection in the absence of preprocessed metadata. We present FedX, a practical framework that enables efficient SPARQL query processing on heterogeneous, virtually integrated Linked Data sources. In experiments, we demonstrate the practicability and efficiency of our framework on a set of real-world queries and data sources from the Linked Open Data cloud. With FedX we achieve a significant improvement in query performance over state-of-the-art federated query engines.},
  file      = {:papers/Optimization Techniques for Federated Query Processing on Linked Data.pdf:PDF},
  groups    = {federated queries},
  isbn      = {978-3-642-25073-6},
}

@InProceedings{Du2012,
  author    = {Du, Fang and Chen, Yueguo and Du, Xiaoyong},
  booktitle = {Database Systems for Advanced Applications},
  title     = {Partitioned Indexes for Entity Search over RDF Knowledge Bases},
  year      = {2012},
  address   = {Berlin, Heidelberg},
  editor    = {Lee, Sang-goo and Peng, Zhiyong and Zhou, Xiaofang and Moon, Yang-Sae and Unland, Rainer and Yoo, Jaesoo},
  pages     = {141--155},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {The rapid growth of RDF data in RDF knowledge bases calls for efficient query processing techniques. This paper focuses on the star-style SPARQL join queries, which is very common when users want to search information of entities from RDF knowledge bases. We observe that the computational cost of such queries mainly comes from loading a large portion of predicate-ahead indexes. We therefore propose to partition the whole RDF knowledge bases based on the schema of individual entities, so that only entities of similar schemas are allocated into the same cluster. Such a partitioning strategy generates a pruning mechanism that effectively isolate the correlations of partitions and the queries. Consequently, queries are only conducted over a small number of partitions with small predicate-ahead indexes. Experiments over a large real-life RDF data set show the significant performance improvements achieved by our partitioned indexing techniques.},
  file      = {:papers/Partitioned Indexes for Entity Search.pdf:PDF},
  groups    = {charateristic set},
  isbn      = {978-3-642-29038-1},
}

@Misc{Taelman2023,
  author     = {Taelman, Ruben and Verborgh, Ruben},
  title      = {Evaluation of Link Traversal Query Execution over Decentralized Environments with Structural Assumptions},
  year       = {2023},
  comment    = {Article très intéressant qui donne une bonne base pour mes expérience, de plus, il a beaucoup de référence qui peuvent m'être utile!},
  copyright  = {Creative Commons Attribution 4.0 International},
  doi        = {10.48550/ARXIV.2302.06933},
  file       = {:papers/Evaluation of Link Traversal ery Execution over Decentralized Environments with Structural Assumptions.pdf:PDF},
  groups     = {Link traversal, Link Traversal Query Processing},
  keywords   = {Databases (cs.DB), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher  = {arXiv},
  ranking    = {rank5},
  readstatus = {read},
  url        = {https://arxiv.org/abs/2302.06933},
}

@Misc{hartig2016walking,
  author        = {Olaf Hartig and M. Tamer Özsu},
  title         = {Walking without a Map: Optimizing Response Times of Traversal-Based Linked Data Queries (Extended Version)},
  year          = {2016},
  archiveprefix = {arXiv},
  eprint        = {1607.01046},
  file          = {:papers/Walking without a Map Optimizing Response Times of Traversal Based Linked Data Queries:},
  groups        = {Link Traversal Query Processing},
  primaryclass  = {cs.DB},
  priority      = {prio1},
}

@InCollection{Hartig2014,
  author     = {Olaf Hartig},
  booktitle  = {Emerging Directions in Database Systems and Applications},
  publisher  = {Chapman and Hall/{CRC}},
  title      = {Linked Data Query Processing Based on Link Traversal},
  year       = {2014},
  month      = may,
  pages      = {263--283},
  doi        = {10.1201/b16859-15},
  file       = {:papers/Linked Data Query Processing Based on Link Traversal.pdf:PDF},
  groups     = {Link Traversal Query Processing, query plan LTQP, query planning},
  ranking    = {rank3},
  readstatus = {skimmed},
  url        = {https://doi.org/10.1201/b16859-15},
}

@InProceedings{Ladwig2010,
  author    = {Ladwig, G{\"u}nter and Tran, Thanh},
  booktitle = {The Semantic Web -- ISWC 2010},
  title     = {Linked Data Query Processing Strategies},
  year      = {2010},
  address   = {Berlin, Heidelberg},
  editor    = {Patel-Schneider, Peter F. and Pan, Yue and Hitzler, Pascal and Mika, Peter and Zhang, Lei and Pan, Jeff Z. and Horrocks, Ian and Glimm, Birte},
  pages     = {453--469},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Recently, processing of queries on linked data has gained attention. We identify and systematically discuss three main strategies: a bottom-up strategy that discovers new sources during query processing by following links between sources, a top-down strategy that relies on complete knowledge about the sources to select and process relevant sources, and a mixed strategy that assumes some incomplete knowledge and discovers new sources at run-time. To exploit knowledge discovered at run-time, we propose an additional step, explicitly scheduled during query processing, called correct source ranking. Additionally, we propose the adoption of stream-based query processing to deal with the unpredictable nature of data access in the distributed Linked Data environment. In experiments, we show that our implementation of the mixed strategy leads to early reporting of results and thus, more responsive query processing, while not requiring complete knowledge.},
  file      = {:papers/Linked Data Query Processing Strategies.pdf:PDF},
  groups    = {Link Traversal Query Processing, query plan LTQP, query planning},
  isbn      = {978-3-642-17746-0},
  priority  = {prio1},
}

@InProceedings{Ladwig2011,
  author     = {Ladwig, G{\"u}nter and Tran, Thanh},
  booktitle  = {The Semantic Web: Research and Applications},
  title      = {SIHJoin: Querying Remote and Local Linked Data},
  year       = {2011},
  address    = {Berlin, Heidelberg},
  editor     = {Antoniou, Grigoris and Grobelnik, Marko and Simperl, Elena and Parsia, Bijan and Plexousakis, Dimitris and De Leenheer, Pieter and Pan, Jeff},
  pages      = {139--153},
  publisher  = {Springer Berlin Heidelberg},
  abstract   = {The amount of Linked Data is increasing steadily. Optimized top-down Linked Data query processing based on complete knowledge about all sources, bottom-up processing based on run-time discovery of sources as well as a mixed strategy that combines them have been proposed. A particular problem with Linked Data processing is that the heterogeneity of the sources and access options lead to varying input latency, rendering the application of blocking join operators infeasible. Previous work partially address this by proposing a non-blocking iterator-based operator and another one based on symmetric-hash join. Here, we propose detailed cost models for these two operators to systematically compare them, and to allow for query optimization. Further, we propose a novel operator called the Symmetric Index Hash Join to address one open problem of Linked Data query processing: to query not only remote, but also local Linked Data. We perform experiments on real-world datasets to compare our approach against the iterator-based baseline, and create a synthetic dataset to more systematically analyze the impacts of the individual components captured by the proposed cost models.},
  comment    = {Article très intéressant qui présente un bon modèle de cout pour des join ainsi que leur implmentation d'un nouvelle algorithm de join dont son coût ne dépend pas du nombre de source ce qui en LTQP est vraiment très bon. Par contre pour le calcul de sélectivité, je ne suis pas sur comment cela ce fait.},
  file       = {:papers/SIHJoin Querying Remote and Local Linked.pdf:PDF},
  groups     = {Link Traversal Query Processing, query plan LTQP, query planning},
  isbn       = {978-3-642-21034-1},
  ranking    = {rank5},
  readstatus = {read},
}

@InProceedings{Hartig2011,
  author    = {Hartig, Olaf},
  booktitle = {The Semantic Web: Research and Applications},
  title     = {Zero-Knowledge Query Planning for an Iterator Implementation of Link Traversal Based Query Execution},
  year      = {2011},
  address   = {Berlin, Heidelberg},
  editor    = {Antoniou, Grigoris and Grobelnik, Marko and Simperl, Elena and Parsia, Bijan and Plexousakis, Dimitris and De Leenheer, Pieter and Pan, Jeff},
  pages     = {154--169},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Link traversal based query execution is a new query execution paradigm for the Web of Data. This approach allows the execution engine to discover potentially relevant data during the query execution and, thus, enables users to tap the full potential of the Web. In earlier work we propose to implement the idea of link traversal based query execution using a synchronous pipeline of iterators. While this idea allows for an easy and efficient implementation, it introduces restrictions that cause less comprehensive result sets. In this paper we address this limitation. We analyze the restrictions and discuss how the evaluation order of a query may affect result set size and query execution costs. To identify a suitable order, we propose a heuristic for our scenario where no a-priory information about relevant data sources is present. We evaluate this heuristic by executing real-world queries over the Web of Data.},
  file      = {:papers/zero knowledge query planning.pdf:PDF},
  groups    = {query plan LTQP, query planning},
  isbn      = {978-3-642-21034-1},
  priority  = {prio1},
}

@Misc{kashif2021,
  author        = {Rabbani, Kashif and Lissandrini, Matteo and Hose, Katja},
  title         = {Optimizing SPARQL Queries using Shape Statistics},
  year          = {2021},
  comment-id357 = {It's a really good paper that describe, and show how to use shape with added statistic plus global void statistic for query planning. I think it can easily be the based for my adaptative approach, I also think that there are some differences with this approach due to the adaptativity and the scoping of the data source.},
  doi           = {10.5441/002/EDBT.2021.59},
  file          = {:papers/Optimizing SPARQL queries using shape statistics.pdf:PDF},
  groups        = {Query plan with shape, query planning},
  keywords      = {Database Technology},
  language      = {en},
  publisher     = {OpenProceedings.org},
  ranking       = {rank5},
  readstatus    = {read},
  url           = {https://openproceedings.org/2021/conf/edbt/p202.pdf},
}

@InProceedings{Haller2023AQA,
  author    = {David Haller},
  booktitle = {PhD@VLDB},
  title     = {A Query-Driven Approach for SHACL Type Inference},
  year      = {2023},
  file      = {:papers/A Query Driven Approach for SHACL Type Inference.pdf:PDF},
  groups    = {Query plan with shape, query planning},
  url       = {https://api.semanticscholar.org/CorpusID:261102495},
}

@InProceedings{Abbas2018,
  author    = {Abbas, Abdullah and Genev{\`e}s, Pierre and Roisin, C{\'e}cile and Laya{\"i}da, Nabil},
  booktitle = {Web Engineering},
  title     = {Selectivity Estimation for SPARQL Triple Patterns with Shape Expressions},
  year      = {2018},
  address   = {Cham},
  editor    = {Mikkonen, Tommi and Klamma, Ralf and Hern{\'a}ndez, Juan},
  pages     = {195--209},
  publisher = {Springer International Publishing},
  abstract  = {We optimize the evaluation of conjunctive SPARQL queries, on big RDF graphs, by taking advantage of ShEx schema constraints. Our optimization is based on computing ranks for query triple patterns, which indicates their order of execution. We first define a set of well-formed ShEx schemas, that possess interesting characteristics for SPARQL query optimization. We then define our optimization method by exploiting information extracted from a ShEx schema. The experimentations performed shows the advantages of applying our optimization on the top of an existing state-of-the-art query evaluation system.},
  file      = {:papers/Selectivity Estimation for SPARQL Triple Patterns with Shape Expressions.pdf:PDF},
  groups    = {Query plan with shape, query planning},
  isbn      = {978-3-319-91662-0},
}

@Article{10.1007/s00778-017-0480-7,
  author     = {Leis, Viktor and Radke, Bernhard and Gubichev, Andrey and Mirchev, Atanas and Boncz, Peter and Kemper, Alfons and Neumann, Thomas},
  journal    = {The VLDB Journal},
  title      = {Query Optimization through the Looking Glass, and What We Found Running the Join Order Benchmark},
  year       = {2018},
  issn       = {1066-8888},
  month      = {oct},
  number     = {5},
  pages      = {643–668},
  volume     = {27},
  abstract   = {Finding a good join order is crucial for query performance. In this paper, we introduce the Join Order Benchmark that works on real-life data riddled with correlations and introduces 113 complex join queries. We experimentally revisit the main components in the classic query optimizer architecture using a complex, real-world data set and realistic multi-join queries. For this purpose, we describe cardinality-estimate injection and extraction techniques that allow us to compare the cardinality estimators of multiple industrial SQL implementations on equal footing, and to characterize the value of having perfect cardinality estimates. Our investigation shows that all industrial-strength cardinality estimators routinely produce large errors: though cardinality estimation using table samples solves the problem for single-table queries, there are still no techniques in industrial systems that can deal accurately with join-crossing correlated query predicates. We further show that while estimates are essential for finding a good join order, query performance is unsatisfactory if the query engine relies too heavily on these estimates. Using another set of experiments that measure the impact of the cost model, we find that it has much less influence on query performance than the cardinality estimates. We investigate plan enumeration techniques comparing exhaustive dynamic programming with heuristic algorithms and find that exhaustive enumeration improves performance despite the suboptimal cardinality estimates. Finally, we extend our investigation from main-memory only, to also include disk-based query processing. Here, we find that though accurate cardinality estimation should be the first priority, other aspects such as modeling random versus sequential I/O are also important to predict query runtime.},
  address    = {Berlin, Heidelberg},
  doi        = {10.1007/s00778-017-0480-7},
  file       = {:papers/Query optimization through the looking glass.pdf:PDF},
  groups     = {query planning},
  issue_date = {October 2018},
  keywords   = {Join ordering, Cardinality estimation, Cost models, Query optimization},
  numpages   = {26},
  publisher  = {Springer-Verlag},
  url        = {https://doi.org/10.1007/s00778-017-0480-7},
}

@Article{Deshpande2007,
  author    = {Amol Deshpande and Zachary Ives and Vijayshankar Raman},
  journal   = {Foundations and Trends{\textregistered} in Databases},
  title     = {Adaptive Query Processing},
  year      = {2007},
  number    = {1},
  pages     = {1--140},
  volume    = {1},
  doi       = {10.1561/1900000001},
  file      = {:papers/Amol Deshpande, Zachary Ives, Vijayshankar Raman - Adaptive Query Processing (Foundations and Trends in Databases) (2007).pdf:PDF},
  groups    = {query planning},
  publisher = {Now Publishers},
  url       = {https://doi.org/10.1561/1900000001},
}

@InProceedings{Gubichev2014ExploitingTQ,
  author    = {Andrey Gubichev and Thomas Neumann},
  booktitle = {International Conference on Extending Database Technology},
  title     = {Exploiting the query structure for efficient join ordering in SPARQL queries},
  year      = {2014},
  file      = {:papers/Exploiting the query structure for efﬁcient join ordering in SPARQL queries.pdf:PDF},
  groups    = {query planning},
  url       = {https://api.semanticscholar.org/CorpusID:2256871},
}

@InProceedings{10.5555/2877789.2877794,
  author    = {Hagedorn, Stefan and Hose, Katja and Sattler, Kai-Uwe and Umbrich, J\"{u}rgen},
  booktitle = {Proceedings of the 5th International Conference on Consuming Linked Data - Volume 1264},
  title     = {Resource Planning for SPARQL Query Execution on Data Sharing Platforms},
  year      = {2014},
  address   = {Aachen, DEU},
  pages     = {49–60},
  publisher = {CEUR-WS.org},
  series    = {COLD'14},
  abstract  = {To increase performance, data sharing platforms often make use of clusters of nodes where certain tasks can be executed in parallel. Resource planning and especially deciding how many processors should be chosen to exploit parallel processing is complex in such a setup as increasing the number of processors does not always improve runtime due to communication overhead. Instead, there is usually an optimum number of processors for which using more or fewer processors leads to less efficient runtimes. In this paper, we present a cost model based on widely used statistics (VoiD) and show how to compute the optimum number of processors that should be used to evaluate a particular SPARQL query over a particular configuration and RDF dataset. Our first experiments show the general applicability of our approach but also how shortcomings in the used statistics limit the potential of optimization.},
  file      = {:papers/Resource Planning for SPARQL Query Execution.pdf:PDF},
  groups    = {query planning},
  location  = {Riva del Garda, Italy},
  numpages  = {12},
}

@Misc{verborgh2020guided,
  author        = {Ruben Verborgh and Ruben Taelman},
  title         = {Guided Link-Traversal-Based Query Processing},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2005.02239},
  groups        = {Link Traversal Query Processing},
  primaryclass  = {cs.DB},
}

@InProceedings{10.1145/2463676.2465231,
  author    = {Hartig, Olaf},
  booktitle = {Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data},
  title     = {SQUIN: A Traversal Based Query Execution System for the Web of Linked Data},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {1081–1084},
  publisher = {Association for Computing Machinery},
  series    = {SIGMOD '13},
  abstract  = {The World Wide Web (WWW) currently evolves into a Web of Linked Data where content providers publish and link their data as they have done with hypertext for the last 20 years. We understand this emerging dataspace as a huge, distributed database which is -at best- partially known to query execution systems. To tap the full potential of the Web, such a system must be able to answer a query using data from initially unknown data sources. For this purpose, traditional query execution paradigms are unsuitable because those assume a fixed set of potentially relevant data sources beforehand.We demonstrate the query execution system SQUIN which implements a novel query execution approach. The main idea is to integrate the traversal of data links into the result construction process. This approach allows the execution engine to discover potentially relevant data during the query execution.In our demonstration, attendees can query the Web of Linked Data using SQUIN and, thus, learn about the new query execution approach. Furthermore, attendees can experience the suitability of the approach for Web applications by using a simple, Linked Data based mash-up implemented on top of SQUIN.},
  doi       = {10.1145/2463676.2465231},
  file      = {:papers/A Traversal Based Query Execution System.pdf:PDF},
  groups    = {Link Traversal Query Processing, query plan LTQP},
  isbn      = {9781450320375},
  keywords  = {web of data, link traversal based query execution, linked data},
  location  = {New York, New York, USA},
  numpages  = {4},
  priority  = {prio1},
  url       = {https://doi.org/10.1145/2463676.2465231},
}

@InProceedings{Miranker2012,
  author     = {Miranker, Daniel and Depena, Rodolfo and Jung, Hyunjoon and Sequeda, Juan},
  title      = {Diamond: A SPARQL Query Engine, for Linked Data Based on the Rete Match},
  year       = {2012},
  month      = {08},
  comment    = {Don't think it is really useful for me},
  file       = {:papers/A SPARQL Query Engine for Linked Data.pdf:PDF},
  groups     = {Link Traversal Query Processing, query plan LTQP},
  ranking    = {rank2},
  readstatus = {skimmed},
}

@InProceedings{Wang2012,
  author    = {Wang, Xin and Tiropanis, Thanassis and Davis, Hugh C.},
  booktitle = {The Semantic Web},
  title     = {Evaluating Graph Traversal Algorithms for Distributed SPARQL Query Optimization},
  year      = {2012},
  address   = {Berlin, Heidelberg},
  editor    = {Pan, Jeff Z. and Chen, Huajun and Kim, Hong-Gee and Li, Juanzi and Wu, Zhe and Horrocks, Ian and Mizoguchi, Riichiro and Wu, Zhaohui},
  pages     = {210--225},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Distributed SPARQL queries enable users to retrieve information by exploiting the increasing amount of linked data being published. However, industrial-strength distributed SPARQL query processing is still at its early stage for efficiently answering queries. Previous research shows that it is possible to apply methods from graph theory to optimize the performance of distributed SPARQL. In this paper we describe a framework that can simulate arbitrary RDF data networks to evaluate different approaches of distributed SPARQL query processing. Using this framework we further explore the graph traversal algorithms for distributed SPARQL optimization. We present an implementation of a Minimum-Spanning-Tree-based (MST-based) algorithm for distributed SPARQL processing, the performance of which is compared to other approaches using this evaluation framework. The contribution of this paper is to show that a MST-based approach seems to perform much better than other non graph-traversal-based approaches, and to provide an evaluation framework for evaluating distributed SPARQL processing.},
  file      = {:papers/Evaluating Graph Traversal Algorithms for Distributed SPARQL Query Optimization.pdf:PDF},
  groups    = {Link Traversal Query Processing},
  isbn      = {978-3-642-29923-0},
  priority  = {prio1},
}

@Article{Sklavos2022EstimatingTC,
  author  = {Anton Sklavos and Pavlos Fafalios and Yannis Tzitzikas},
  journal = {ArXiv},
  title   = {Estimating the Cost of Executing Link Traversal based SPARQL Queries},
  year    = {2022},
  volume  = {abs/2210.09100},
  file    = {:papers/Estimating the Cost of Executing Link Traversal based SPARQL Queries.pdf:PDF},
  groups  = {Link Traversal Query Processing},
  url     = {https://api.semanticscholar.org/CorpusID:252917692},
}

@InProceedings{Bogaerts2021LinkTW,
  author    = {Bart Bogaerts and Bas Ketsman and Younes Zeboudj and Heba Aamer and Ruben Taelman and Ruben Verborgh},
  booktitle = {RuleML+RR},
  title     = {Link Traversal with Distributed Subweb Specifications},
  year      = {2021},
  groups    = {Link Traversal Query Processing},
  url       = {https://api.semanticscholar.org/CorpusID:244848944},
}

@Article{Alahmari2011EvaluatingSU,
  author  = {Fahad Alahmari},
  journal = {2011 Sixth International Conference on Digital Information Management},
  title   = {Evaluating SPARQL using query federation and link traversal},
  year    = {2011},
  pages   = {79-84},
  file    = {:papers/Evaluating SPARQL Using Query Federation and Link Traversal.pdf:PDF},
  groups  = {Link Traversal Query Processing},
  url     = {https://api.semanticscholar.org/CorpusID:17066695},
}

@InProceedings{Harth2016LinkTA,
  author = {A. Harth},
  title  = {Link traversal and reasoning in dynamic linked data knowledge bases},
  year   = {2016},
  file   = {:papers/Link Traversal and Reasoning in Dynamic Linked Data Knowledge Bases.pdf:PDF},
  groups = {Link Traversal Query Processing},
  url    = {https://api.semanticscholar.org/CorpusID:56854840},
}

@InProceedings{10.1145/1772690.1772733,
  author    = {Harth, Andreas and Hose, Katja and Karnstedt, Marcel and Polleres, Axel and Sattler, Kai-Uwe and Umbrich, J\"{u}rgen},
  booktitle = {Proceedings of the 19th International Conference on World Wide Web},
  title     = {Data Summaries for On-Demand Queries over Linked Data},
  year      = {2010},
  address   = {New York, NY, USA},
  pages     = {411–420},
  publisher = {Association for Computing Machinery},
  series    = {WWW '10},
  abstract  = {Typical approaches for querying structured Web Data collect (crawl) and pre-process (index) large amounts of data in a central data repository before allowing for query answering. However, this time-consuming pre-processing phase however leverages the benefits of Linked Data -- where structured data is accessible live and up-to-date at distributed Web resources that may change constantly -- only to a limited degree, as query results can never be current. An ideal query answering system for Linked Data should return current answers in a reasonable amount of time, even on corpora as large as the Web. Query processors evaluating queries directly on the live sources require knowledge of the contents of data sources. In this paper, we develop and evaluate an approximate index structure summarising graph-structured content of sources adhering to Linked Data principles, provide an algorithm for answering conjunctive queries over Linked Data on theWeb exploiting the source summary, and evaluate the system using synthetically generated queries. The experimental results show that our lightweight index structure enables complete and up-to-date query results over Linked Data, while keeping the overhead for querying low and providing a satisfying source ranking at no additional cost.},
  doi       = {10.1145/1772690.1772733},
  file      = {:papers/Data Summaries for On Demand Queries over Linked Data.pdf:PDF},
  groups    = {Link Traversal Query Processing, query plan LTQP},
  isbn      = {9781605587998},
  keywords  = {index structures, rdf querying, linked data},
  location  = {Raleigh, North Carolina, USA},
  numpages  = {10},
  url       = {https://doi.org/10.1145/1772690.1772733},
}

@InProceedings{10.1007/978-3-642-04930-9_19,
  author    = {Hartig, Olaf and Bizer, Christian and Freytag, Johann-Christoph},
  booktitle = {Proceedings of the 8th International Semantic Web Conference},
  title     = {Executing SPARQL Queries over the Web of Linked Data},
  year      = {2009},
  address   = {Berlin, Heidelberg},
  pages     = {293–309},
  publisher = {Springer-Verlag},
  series    = {ISWC '09},
  abstract  = {The Web of Linked Data forms a single, globally distributed dataspace. Due to the openness of this dataspace, it is not possible to know in advance all data sources that might be relevant for query answering. This openness poses a new challenge that is not addressed by traditional research on federated query processing. In this paper we present an approach to execute SPARQL queries over the Web of Linked Data. The main idea of our approach is to discover data that might be relevant for answering a query during the query execution itself. This discovery is driven by following RDF links between data sources based on URIs in the query and in partial results. The URIs are resolved over the HTTP protocol into RDF data which is continuously added to the queried dataset. This paper describes concepts and algorithms to implement our approach using an iterator-based pipeline. We introduce a formalization of the pipelining approach and show that classical iterators may cause blocking due to the latency of HTTP requests. To avoid blocking, we propose an extension of the iterator paradigm. The evaluation of our approach shows its strengths as well as the still existing challenges.},
  doi       = {10.1007/978-3-642-04930-9_19},
  file      = {:papers/Executing SPARQL Queries over the Web of Linked Data.pdf:PDF},
  groups    = {Link Traversal Query Processing},
  isbn      = {9783642049293},
  location  = {Chantilly, VA},
  numpages  = {17},
  url       = {https://doi.org/10.1007/978-3-642-04930-9_19},
}

@InProceedings{Thapa2023,
  author        = {Thapa, Ratan Bahadur and Giese, Martin},
  booktitle     = {The Semantic Web -- ISWC 2023},
  title         = {Optimizing SPARQL Queries with SHACL},
  year          = {2023},
  address       = {Cham},
  editor        = {Payne, Terry R. and Presutti, Valentina and Qi, Guilin and Poveda-Villal{\'o}n, Mar{\'i}a and Stoilos, Giorgos and Hollink, Laura and Kaoudi, Zoi and Cheng, Gong and Li, Juanzi},
  pages         = {41--60},
  publisher     = {Springer Nature Switzerland},
  abstract      = {We propose a set of optimizations that can be applied to a given SPARQL query, and that guarantee that the optimized query has the same answers under bag semantics as the original query, provided that the queried RDF graph validates certain SHACL constraints. Our optimizations exploit the relationship between graph patterns in the SPARQL queries and the SHACL constraints that describe those patterns in the RDF graph. We prove the correctness of these optimizations and show how they can be propagated to larger queries while preserving answers. Further, we prove the confluence of rewritings that employ these optimizations, guaranteeing convergence to the same optimized query regardless of the rewriting order.},
  comment-id357 = {Formulate multiple optimization using shape could be useful for once motivate shapes, second as an inspiration for our own formulations},
  file          = {:papers/Optimizing SPARQL queries with SHACL.pdf:PDF},
  groups        = {query containment with RDF},
  isbn          = {978-3-031-47240-4},
  priority      = {prio1},
}

@InProceedings{Asprino2023,
  author    = {Asprino, Luigi and Ceriani, Miguel},
  booktitle = {The Semantic Web -- ISWC 2023},
  title     = {How is Your Knowledge Graph Used: Content-Centric Analysis of SPARQL Query Logs},
  year      = {2023},
  address   = {Cham},
  editor    = {Payne, Terry R. and Presutti, Valentina and Qi, Guilin and Poveda-Villal{\'o}n, Mar{\'i}a and Stoilos, Giorgos and Hollink, Laura and Kaoudi, Zoi and Cheng, Gong and Li, Juanzi},
  pages     = {197--215},
  publisher = {Springer Nature Switzerland},
  abstract  = {Knowledge graphs (KGs) are used to integrate and persist information useful to organisations, communities, or the general public. It is essential to understand how KGs are used so as to evaluate the strengths and shortcomings of semantic web standards, data modelling choices formalised in ontologies, deployment settings of triple stores etc. One source of information on the usage of the KGs is the query logs, but making sense of hundreds of thousands of log entries is not trivial. Previous works that studied available logs from public SPARQL endpoints mainly focused on the general syntactic properties of the queries disregarding the semantics and their intent. We introduce a novel, content-centric, approach that we call query log summarisation, in which we group the queries that can be derived from some common pattern. The type of patterns considered in this work is query templates, i.e. common blueprints from which multiple queries can be generated by the replacement of parameters with constants. Moreover, we present an algorithm able to summarise a query log as a list of templates whose time and space complexity is linear with respect to the size of the input (number and dimension of queries). We experimented with the algorithm on the query logs of the Linked SPARQL Queries dataset showing promising results.},
  file      = {:papers/The Semantic Web –_ISWC 2023.pdf:PDF},
  groups    = {analysis of KG},
  isbn      = {978-3-031-47240-4},
}

@InProceedings{10.1145/1066157.1066171,
  author    = {Babu, Shivnath and Bizarro, Pedro and DeWitt, David},
  booktitle = {Proceedings of the 2005 ACM SIGMOD International Conference on Management of Data},
  title     = {Proactive Re-Optimization},
  year      = {2005},
  address   = {New York, NY, USA},
  pages     = {107–118},
  publisher = {Association for Computing Machinery},
  series    = {SIGMOD '05},
  abstract  = {Traditional query optimizers rely on the accuracy of estimated statistics to choose good execution plans. This design often leads to suboptimal plan choices for complex queries, since errors in estimates for intermediate subexpressions grow exponentially in the presence of skewed and correlated data distributions. Reoptimization is a promising technique to cope with such mistakes. Current re-optimizers first use a traditional optimizer to pick a plan, and then react to estimation errors and resulting suboptimalities detected in the plan during execution. The effectiveness of this approach is limited because traditional optimizers choose plans unaware of issues affecting reoptimization. We address this problem using proactive reoptimization, a new approach that incorporates three techniques: i) the uncertainty in estimates of statistics is computed in the form of bounding boxes around these estimates, ii) these bounding boxes are used to pick plans that are robust to deviations of actual values from their estimates, and iii) accurate measurements of statistics are collected quickly and efficiently during query execution. We present an extensive evaluation of these techniques using a prototype proactive re-optimizer named Rio. In our experiments Rio outperforms current re-optimizers by up to a factor of three.},
  doi       = {10.1145/1066157.1066171},
  file      = {:papers/Proactive Re-Optimization.pdf:PDF},
  groups    = {query planning},
  isbn      = {1595930604},
  location  = {Baltimore, Maryland},
  numpages  = {12},
  url       = {https://doi.org/10.1145/1066157.1066171},
}

@InBook{Gayo2018,
  author    = {Gayo, Jose Emilio Labra and Prud'hommeaux, Eric and Boneva, Iovka and Kontokostas, Dimitris},
  pages     = {55--117},
  publisher = {Springer International Publishing},
  title     = {Shape Expressions},
  year      = {2018},
  address   = {Cham},
  isbn      = {978-3-031-79478-0},
  abstract  = {Shape Expressions (ShEx) is a schema language for describing RDF graphs structures. ShEx was originally developed in late 2013 to provide a human-readable syntax for OSLC Resource Shapes. It added disjunctions, so it was more expressive than Resource Shapes. Tokens in the language were adopted from Turtle [80] and SPARQL [44] with tokens for grouping, repetition and wildcards from regular expression and RelaxNG Compact Syntax [100]. The language was described in a paper [80] and codified in a June 2014 W3C member submission [92] which included a primer and a semantics specification. This was later deemed ``ShEx 1.0''.},
  booktitle = {Validating RDF Data},
  doi       = {10.1007/978-3-031-79478-0_4},
  file      = {:papers/shape_expressions.pdf:PDF},
  groups    = {shape},
  url       = {https://doi.org/10.1007/978-3-031-79478-0_4},
}

@InBook{Gayo2018a,
  author    = {Gayo, Jose Emilio Labra and Prud'hommeaux, Eric and Boneva, Iovka and Kontokostas, Dimitris},
  pages     = {195--231},
  publisher = {Springer International Publishing},
  title     = {Applications},
  year      = {2018},
  address   = {Cham},
  isbn      = {978-3-031-79478-0},
  abstract  = {In this chapter we describe several applications of RDF validation. We start with the WebIndex, a medium-size linked data portal that was one of the earliest applications of ShEx. We describe it using ShEx and SHACL so the reader can see how both formalisms can be applied to describe RDF data.},
  booktitle = {Validating RDF Data},
  doi       = {10.1007/978-3-031-79478-0_6},
  file      = {:papers/applications.pdf:PDF},
  groups    = {shape},
  url       = {https://doi.org/10.1007/978-3-031-79478-0_6},
}

@InBook{Gayo2018b,
  author    = {Gayo, Jose Emilio Labra and Prud'hommeaux, Eric and Boneva, Iovka and Kontokostas, Dimitris},
  pages     = {119--194},
  publisher = {Springer International Publishing},
  title     = {SHACL},
  year      = {2018},
  address   = {Cham},
  isbn      = {978-3-031-79478-0},
  abstract  = {Shapes Constraint Language (SHACL) has been developed by the W3C RDF Data Shapes Working Group, which was chartered in 2014 with the goal to ``produce a language for defining structural constraints on RDF graphs [6].''},
  booktitle = {Validating RDF Data},
  doi       = {10.1007/978-3-031-79478-0_5},
  file      = {:papers/shacl.pdf:PDF},
  groups    = {shape},
  url       = {https://doi.org/10.1007/978-3-031-79478-0_5},
}

@InBook{Gayo2018c,
  author    = {Gayo, Jose Emilio Labra and Prud'hommeaux, Eric and Boneva, Iovka and Kontokostas, Dimitris},
  pages     = {233--266},
  publisher = {Springer International Publishing},
  title     = {Comparing ShEx and SHACL},
  year      = {2018},
  address   = {Cham},
  isbn      = {978-3-031-79478-0},
  abstract  = {In this chapter we present a comparison between ShEx and SHACL. The technologies have similar goals and similar features. In fact at the start of the Data Shapes Working Group in 2014, convergence on a unified approach was considered possible. However, this did not happen and as of July 2017 both technologies are maintained as separate solutions.},
  booktitle = {Validating RDF Data},
  doi       = {10.1007/978-3-031-79478-0_7},
  file      = {:papers/Comparing ShEx and SHACL.pdf:PDF},
  groups    = {shape},
  url       = {https://doi.org/10.1007/978-3-031-79478-0_7},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:charateristic set\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:federated queries\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Link Traversal Query Processing\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:query containment\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:query containment bag semantic\;0\;0\;0x8a8a8aff\;\;\;;
1 StaticGroup:query containment with RDF\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:query decomposition\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:query plan LTQP\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Query plan with shape\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:query planning\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:reading\;0\;0\;0x8a8a8aff\;\;\;;
1 StaticGroup:shape\;0\;0\;0x8a8a8aff\;\;\;;
1 StaticGroup:shape containment\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:protocol\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:analysis of KG\;0\;1\;0x8a8a8aff\;\;\;;
}
